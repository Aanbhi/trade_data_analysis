{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"elapsed":194890,"status":"ok","timestamp":1739433551553,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"adz8xwYg3R4b","outputId":"daa48bb2-16aa-49ee-8000-9c16fb736dcb"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-3b2063c3-a805-4837-879b-2b98d301e795\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3b2063c3-a805-4837-879b-2b98d301e795\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving compressed_data.csv.gz to compressed_data.csv.gz\n"]}],"source":["# Step 1: Import required libraries\n","import pandas as pd\n","import numpy as np\n","import json\n","# Import the 're' module for regular expressions\n","import re  # This line is added to import the 're' module\n","from google.colab import files\n","uploaded = files.upload()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1231,"status":"ok","timestamp":1739433569870,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"1H5JCaWJlNS1","outputId":"06c22008-fec2-4e98-93aa-ca261e9d03da"},"outputs":[{"name":"stdout","output_type":"stream","text":["              Port_IDs                                      Trade_History\n","0  3925368433214965504  [{'time': 1718899656000, 'symbol': 'SOLUSDT', ...\n","1  4002413037164645377  [{'time': 1718980078000, 'symbol': 'NEARUSDT',...\n","2  3923766029921022977  [{'time': 1718677164000, 'symbol': 'ETHUSDT', ...\n","3  3994879592543698688  [{'time': 1718678214000, 'symbol': 'ETHUSDT', ...\n","4  3926423286576838657  [{'time': 1718979615000, 'symbol': 'ETHUSDT', ...\n"]}],"source":["import pandas as pd\n","# Assuming your uploaded file is named \"trades.csv\"\n","data = pd.read_csv(\"compressed_data.csv.gz\")\n","print(data.head())"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1923,"status":"ok","timestamp":1739435701241,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"C3yF0QZ75hhK"},"outputs":[],"source":["\n","# Step 3: Parse and clean data\n","# Assume 'Trade_History' is a nested column with JSON-like strings that need flattening.\n","if 'Trade_History' in data.columns:\n","    # Convert non-string values to valid JSON strings (e.g., empty dictionaries)\n","    data['Trade_History'] = data['Trade_History'].apply(lambda x: x if isinstance(x, str) else '{}')\n","\n","    # Define a function to clean JSON strings\n","    def clean_json(json_string):\n","        # Replace single quotes with double quotes for keys\n","        json_string = re.sub(r\"(\\w+)\\s*:\", r'\"\\1\":', json_string)\n","        # Replace single quotes with double quotes for values if they are not numbers or booleans\n","        json_string = re.sub(r\":\\s*'([^']*)'\", r': \"\\1\"', json_string)\n","        # Remove extra spaces and newlines\n","        json_string = re.sub(r'\\s+', ' ', json_string)\n","\n","        try:\n","            # Attempt to parse the cleaned JSON string\n","            json_data = json.loads(json_string)\n","            return json_string # Return the cleaned string if parsing is successful\n","        except json.JSONDecodeError as e:\n","            # Handle cases where cleaning didn't fix the JSON\n","            print(f\"Error parsing JSON: {e}, Original string: {json_string}\")  # Print error for debugging\n","            return '{}'  # Return an empty dictionary as a fallback\n","\n","    # Apply the cleaning function to the 'Trade_History' column\n","    data['Trade_History'] = data['Trade_History'].apply(clean_json)\n","\n","    # Use json.loads instead of eval for safer and more robust JSON parsing\n","    trade_history = pd.json_normalize(data['Trade_History'].apply(json.loads))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1739435705664,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"BdLVoiWoXKCa","outputId":"6ade607a-4c06-4693-c2e7-4eb0b6aa3163"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error: 'side' column not found. Check your data and parsing logic.\n","Fix the missing 'side' column issue before continuing.\n"]}],"source":["# Step 4: Group data by Port_ID for metric calculations\n","\n","# Check if the 'side' column exists\n","if 'side' in data.columns:\n","    # Proceed to group by 'Port_IDs' if 'side' column exists\n","    grouped = data.groupby(\"Port_IDs\")\n","else:\n","    # If 'side' column is missing, print an error and stop execution\n","    print(\"Error: 'side' column not found. Check your data and parsing logic.\")\n","    grouped = None  # Set grouped to None to avoid further errors\n","\n","# Ensure further code only runs if grouping was successful\n","if grouped is not None:\n","    print(\"Data successfully grouped by 'Port_IDs'. Proceeding with calculations.\")\n","    # Add further processing logic here\n","else:\n","    print(\"Fix the missing 'side' column issue before continuing.\")\n","\n","if 'Port_IDs' not in data.columns:\n","    print(\"Error: 'Port_IDs' column not found. Please check your dataset.\")\n","\n","grouped = data.groupby(\"Port_IDs\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"1D2S8q8nXMAP","executionInfo":{"status":"ok","timestamp":1739435718546,"user_tz":-330,"elapsed":619,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"}}},"outputs":[],"source":["\n","# Step 5: Define functions to calculate financial metrics\n","# ROI (Return on Investment)\n","def calculate_roi(trades):\n","    # Check if 'side' column exists before accessing it\n","    if 'side' in trades.columns:\n","        total_investment = trades.loc[trades['side'] == 'BUY', 'quantity'].sum()\n","    else:\n","        total_investment = 0  # Or handle it appropriately for your use case\n","    total_profit = trades['realizedProfit'].sum()\n","    roi = (total_profit / total_investment) * 100 if total_investment > 0 else 0\n","    return total_investment, total_profit, roi\n","\n","# Sharpe Ratio\n","def calculate_sharpe_ratio(trades):\n","    returns = trades[\"realizedProfit\"]\n","    if len(returns) > 1:\n","        return_mean = returns.mean()\n","        return_std = returns.std()\n","        return return_mean / return_std if return_std != 0 else np.nan\n","    return np.nan"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":851,"status":"ok","timestamp":1739435724466,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"tesvm3BQbCT7","outputId":"7bdc67a9-1afc-44f2-cbd8-c8c8b10a27c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Port_IDs', 'Trade_History'], dtype='object')\n"]}],"source":["print(data.columns)\n","grouped = data.groupby(\"Port_IDs\")\n","if 'realizedProfit' not in data.columns:\n","    data['realizedProfit'] = data.get('profit', 0)  # Replace 'profit' with the actual column name."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"7HPjVDKtRHOW","executionInfo":{"status":"ok","timestamp":1739435735922,"user_tz":-330,"elapsed":547,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"}}},"outputs":[],"source":["# Win Rate and Positions\n","def calculate_win_rate(trades):\n","    if 'realizedProfit' not in trades.columns:\n","        raise KeyError(\"'realizedProfit' column is missing in the DataFrame.\")\n","    total_positions = len(trades)\n","    win_positions = len(trades[trades[\"realizedProfit\"] > 0])\n","    win_rate = (win_positions / total_positions) * 100 if total_positions > 0 else 0\n","    return win_positions, total_positions, win_rate\n","\n","# Maximum Drawdown (MDD)\n","def calculate_mdd(trades):\n","    if 'realizedProfit' not in trades.columns:\n","        raise KeyError(\"'realizedProfit' column is missing in the DataFrame.\")\n","    cumulative_pnl = trades[\"realizedProfit\"].cumsum()\n","    rolling_max = cumulative_pnl.cummax()\n","    drawdown = rolling_max - cumulative_pnl\n","    mdd = drawdown.max()\n","    return mdd\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1739435741967,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"fpdcxZAn8sYV","outputId":"570518b9-2605-4d0a-ce79-f4958d4da2c2"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-411649a61a4d>:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  roi_df = grouped.apply(lambda x: pd.Series(calculate_roi(x), index=[\"Total_Investment\", \"Total_Profit\", \"ROI\"])).reset_index()\n","<ipython-input-15-411649a61a4d>:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  sharpe_df = grouped.apply(calculate_sharpe_ratio).reset_index()\n","<ipython-input-15-411649a61a4d>:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  win_rate_df = grouped.apply(lambda x: calculate_win_rate(x)).reset_index()\n","<ipython-input-15-411649a61a4d>:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  mdd_df = grouped.apply(calculate_mdd).reset_index()\n"]}],"source":["\n","# Check and group data\n","if \"Port_IDs\" not in data.columns:\n","    raise KeyError(\"'Port_IDs' column is missing in the DataFrame.\")\n","\n","grouped = data.groupby(\"Port_IDs\")\n","\n","# Step 6: Calculate metrics for each account\n","roi_df = grouped.apply(lambda x: pd.Series(calculate_roi(x), index=[\"Total_Investment\", \"Total_Profit\", \"ROI\"])).reset_index()\n","sharpe_df = grouped.apply(calculate_sharpe_ratio).reset_index()\n","sharpe_df.columns = [\"Port_IDs\", \"Sharpe_Ratio\"]\n","win_rate_df = grouped.apply(lambda x: calculate_win_rate(x)).reset_index()\n","win_rate_df.columns = [\"Port_IDs\", \"Win_Positions_Tuple\"]\n","win_rate_df[[\"Win_Positions\", \"Total_Positions\", \"Win_Rate\"]] = pd.DataFrame(win_rate_df[\"Win_Positions_Tuple\"].tolist(), index=win_rate_df.index)\n","win_rate_df = win_rate_df.drop(columns=[\"Win_Positions_Tuple\"])\n","mdd_df = grouped.apply(calculate_mdd).reset_index()\n","mdd_df.columns = [\"Port_IDs\", \"MDD\"]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1058,"status":"ok","timestamp":1739435749422,"user":{"displayName":"Anbhi Thakur","userId":"17661229481021192238"},"user_tz":-330},"id":"2wWOBlccJuty","outputId":"788af83e-e19f-4c4b-a08f-95078b91cb3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Full metrics saved as 'all_metrics.csv'\n","Top 20 accounts saved as 'top_20_accounts.csv'\n"]}],"source":["# Step 7: Combine all metrics into one DataFrame\n","metrics_df = roi_df.merge(sharpe_df, on=\"Port_IDs\").merge(win_rate_df, on=\"Port_IDs\").merge(mdd_df, on=\"Port_IDs\")\n","\n","# Step 8: Normalize metrics and calculate weighted score for ranking\n","weights = {\n","    \"ROI\": 0.4,\n","    \"PnL\": 0.3,\n","    \"Sharpe_Ratio\": 0.2,\n","    \"Win_Rate\": 0.1,\n","    \"MDD\": -0.1,\n","}\n","\n","for col in [\"ROI\", \"Total_Profit\", \"Sharpe_Ratio\", \"Win_Rate\", \"MDD\"]:\n","    if col == \"MDD\":\n","        metrics_df[col + \"_Normalized\"] = 1 - (metrics_df[col] / metrics_df[col].max())\n","    else:\n","        metrics_df[col + \"_Normalized\"] = metrics_df[col] / metrics_df[col].max()\n","\n","metrics_df[\"Weighted_Score\"] = (\n","    metrics_df[\"ROI_Normalized\"] * weights[\"ROI\"]\n","    + metrics_df[\"Total_Profit_Normalized\"] * weights[\"PnL\"]\n","    + metrics_df[\"Sharpe_Ratio_Normalized\"] * weights[\"Sharpe_Ratio\"]\n","    + metrics_df[\"Win_Rate_Normalized\"] * weights[\"Win_Rate\"]\n","    + metrics_df[\"MDD_Normalized\"] * weights[\"MDD\"]\n",")\n","\n","metrics_df[\"Rank\"] = metrics_df[\"Weighted_Score\"].rank(ascending=False)\n","\n","# Step 9: Extract the top 20 accounts\n","top_20_accounts = metrics_df.sort_values(by=\"Rank\").head(20)\n","\n","# Step 10: Save results to CSV files\n","metrics_df.to_csv(\"all_metrics.csv\", index=False)\n","top_20_accounts.to_csv(\"top_20_accounts.csv\", index=False)\n","\n","# Print file paths for download\n","print(\"Full metrics saved as 'all_metrics.csv'\")\n","print(\"Top 20 accounts saved as 'top_20_accounts.csv'\")"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbHmEYn0vIigr+3pk7rm1w"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}